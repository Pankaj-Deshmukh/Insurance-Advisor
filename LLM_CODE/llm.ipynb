{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import all the required libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer,util\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import all the required libraries\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load your CSV data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/pankaj-deshmukh/LocalSend/data_final1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m (df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load your CSV data\n",
    "df = pd.read_csv('/home/pankaj-deshmukh/LocalSend/data_final1.csv')\n",
    "(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained sentence transformer model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Encode the DataFrame rows\n",
    "df['combined_str'] = df['combined_str'].apply(lambda x: model.encode(x))\n",
    "# data.head()\n",
    "\n",
    "def get_similar_items(combined_input, df, model, top_n=5):\n",
    "    combined_embedding = model.encode(combined_input)\n",
    "    # Calculate cosine similarity between the combined input and all other combined texts\n",
    "    similarities = util.pytorch_cos_sim(combined_embedding, df['combined_str'])\n",
    "    #print(similarities)\n",
    "    # Get the indices of top N similar items\n",
    "    similar_indices = similarities.argsort(descending=True, axis=1)[0][:top_n]\n",
    "    #print(similar_indices)\n",
    "    # Retrieve the similar items from the DataFrame\n",
    "    similar_items_df = df.iloc[similar_indices][['age', 'Term', 'Plan', 'Company', 'premium']].reset_index(drop=True)\n",
    "    # print(similar_items)\n",
    "    return similar_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_ollama(prompt):\n",
    "    # Modify this command to suit your local LLM API or interaction method\n",
    "    result = subprocess.run(['ollama', 'run', 'mistral'], input=prompt, capture_output=True, text=True) # change it to llama3 for better response but it is slow.\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pankaj-deshmukh/.local/lib/python3.10/site-packages/sentence_transformers/util.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  a = torch.tensor(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function get_similar_items at 0x762f79d7fbe0>\n",
      "Relevant Response Retrieved:\n",
      "   age  Term                   Plan                              Company  \\\n",
      "0   24     7  Click 2 Protect Super  HDFC Life Insurance Company Limited   \n",
      "1   19     7  Click 2 Protect Super  HDFC Life Insurance Company Limited   \n",
      "2   18     7  Click 2 Protect Super  HDFC Life Insurance Company Limited   \n",
      "3   23     7  Click 2 Protect Super  HDFC Life Insurance Company Limited   \n",
      "4   19     6  Click 2 Protect Super  HDFC Life Insurance Company Limited   \n",
      "\n",
      "   premium  \n",
      "0     9898  \n",
      "1     9605  \n",
      "2     9605  \n",
      "3     9730  \n",
      "4    10178  \n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"give me hdfc policies\"\n",
    "response = get_similar_items(query, df, model)\n",
    "print(\"Relevant Response Retrieved:\")\n",
    "print(response)\n",
    "\n",
    "# Combine retrieved data with the query to generate a detailed response\n",
    "detailed_prompt = f\"Based on the data:\\n {response.to_dict()},\\n Assume your a policy advisor, explain the given policies row wise for the given question: '{query}':\"\n",
    "final_response = generate_response_with_ollama(detailed_prompt)\n",
    "print(final_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
